{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zig302/ML_testing/blob/main/Prefetch_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Imports* and config"
      ],
      "metadata": {
        "id": "jfkpyLqAXzq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# CONFIG\n",
        "CSV_FILE       = \"memory_accesses_pc_va.csv\"\n",
        "HISTORY_LENGTH = 16            # Sliding history window size\n",
        "TOP_DELTAS     = 128           # K most frequent deltas to predict\n",
        "BATCH_SIZE     = 512\n",
        "NUM_EPOCHS     = 50\n",
        "LEARNING_RATE  = 1e-3\n",
        "TEST_SIZE      = 0.2           # 20% for validation"
      ],
      "metadata": {
        "id": "kiHs-G-gFZr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QW15P3xBkCPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading, filtering and preparing data"
      ],
      "metadata": {
        "id": "p41wPxRkFnvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD & FILTER\n",
        "df = pd.read_csv(CSV_FILE)\n",
        "# Keep only cache misses\n",
        "df = df[df['cache_hit'] == 0].reset_index(drop=True)  # filter misses\n",
        "\n",
        "# COMPUTE CACHE-BLOCK & DELTA\n",
        "# Convert hex string addr -> int, then to 64-byte cache-line index\n",
        "df['block'] = df['addr'].apply(lambda x: int(x, 16) // 64)\n",
        "# Predict delta = block_t - block_{t-1}\n",
        "df['delta'] = df['block'].diff().fillna(0).astype(int)\n",
        "\n",
        "# BUILD TOP-K DELTA VOCAB & FILTER\n",
        "top_deltas = df['delta'].value_counts().nlargest(TOP_DELTAS).index\n",
        "# Keep only rows whose delta is in top-K\n",
        "df = df[df['delta'].isin(top_deltas)].reset_index(drop=True)\n",
        "# Map delta -> 0..K-1 label\n",
        "delta2id = {d:i for i,d in enumerate(top_deltas)}\n",
        "df['delta_id'] = df['delta'].map(delta2id)\n",
        "\n",
        "# ENCODE PCs\n",
        "# Convert hex string ip -> int, then to categorical ID\n",
        "df['pc_int'] = df['ip'].apply(lambda x: int(x,16))\n",
        "unique_pcs = df['pc_int'].unique()\n",
        "pc2id = {pc:i for i,pc in enumerate(unique_pcs)}\n",
        "df['pc_id'] = df['pc_int'].map(pc2id)\n",
        "\n",
        "# BUILD SLIDING WINDOWS (history -> next-delta label)\n",
        "X_pc    = []\n",
        "X_delta = []\n",
        "y       = []\n",
        "for i in range(HISTORY_LENGTH, len(df)):\n",
        "    # history of PCs and deltas\n",
        "    X_pc.append(   df['pc_id'].iloc[i-HISTORY_LENGTH:i].values )\n",
        "    X_delta.append(df['delta_id'].iloc[i-HISTORY_LENGTH:i].values )\n",
        "    # label is the delta at time i\n",
        "    y.append( df['delta_id'].iloc[i] )\n",
        "\n",
        "X_pc    = np.stack(X_pc)        # shape [N_windows, HISTORY_LENGTH]\n",
        "X_delta = np.stack(X_delta)\n",
        "y       = np.array(y)"
      ],
      "metadata": {
        "id": "NDK32yqFFr8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Val split and DataLoader"
      ],
      "metadata": {
        "id": "CBSpU7c9F5_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAIN/VAL SPLIT\n",
        "X_pc_tr, X_pc_val, X_delta_tr, X_delta_val, y_tr, y_val = train_test_split(\n",
        "    X_pc, X_delta, y,\n",
        "    test_size=TEST_SIZE,\n",
        "    random_state=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# DATASET & DATALOADER\n",
        "class PrefetchDeltaDataset(Dataset):\n",
        "    def __init__(self, pcs, deltas, labels):\n",
        "        self.pcs    = torch.LongTensor(pcs)\n",
        "        self.deltas = torch.LongTensor(deltas)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.pcs[idx], self.deltas[idx]), self.labels[idx]\n",
        "\n",
        "train_ds = PrefetchDeltaDataset(X_pc_tr, X_delta_tr, y_tr)\n",
        "val_ds   = PrefetchDeltaDataset(X_pc_val, X_delta_val, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "kiuHUT7pF_Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Model"
      ],
      "metadata": {
        "id": "boNu-IRYGBFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) MODEL: Deep 1D-CNN on (pc, delta) sequence\n",
        "class PrefetchCNN(nn.Module):\n",
        "    def __init__(self, n_pcs, n_deltas,\n",
        "                 pc_emb=64, delta_emb=16,\n",
        "                 hidden=128, kernel=3, hist=HISTORY_LENGTH,\n",
        "                 n_classes=TOP_DELTAS, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.pc_embed    = nn.Embedding(n_pcs,    pc_emb)\n",
        "        self.delta_embed = nn.Embedding(n_deltas, delta_emb)\n",
        "        in_ch = pc_emb + delta_emb\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_ch, hidden, kernel, padding=kernel//2)\n",
        "        self.bn1   = nn.BatchNorm1d(hidden)\n",
        "        self.conv2 = nn.Conv1d(hidden, hidden, kernel, padding=kernel//2)\n",
        "        self.bn2   = nn.BatchNorm1d(hidden)\n",
        "        self.conv3 = nn.Conv1d(hidden, hidden, kernel, padding=kernel//2)\n",
        "        self.bn3   = nn.BatchNorm1d(hidden)\n",
        "\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc   = nn.Linear(hidden, n_classes)\n",
        "\n",
        "    def forward(self, pc_seq, delta_seq):\n",
        "        p = self.pc_embed(pc_seq)          # [B, H, pc_emb]\n",
        "        d = self.delta_embed(delta_seq)    # [B, H, delta_emb]\n",
        "        x = torch.cat([p, d], dim=2)       # [B, H, in_ch]\n",
        "        x = x.transpose(1, 2)              # [B, in_ch, H]\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.drop(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.drop(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.drop(x)\n",
        "\n",
        "        x = self.pool(x).view(x.size(0), -1)\n",
        "        return self.fc(x)                  # [B, TOP_DELTAS]"
      ],
      "metadata": {
        "id": "qE02Wxl7GCSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "7_TCPwWMGH6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PrefetchCNN(n_pcs=len(unique_pcs), n_deltas=len(top_deltas)).to(device)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    # Train\n",
        "    model.train()\n",
        "    total, correct = 0, 0\n",
        "    for (pc_b, d_b), y_b in train_loader:\n",
        "        pc_b, d_b, y_b = pc_b.to(device), d_b.to(device), y_b.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits = model(pc_b, d_b)\n",
        "        loss   = F.cross_entropy(logits, y_b)\n",
        "        loss.backward(); opt.step()\n",
        "\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total += y_b.size(0)\n",
        "        correct += (preds == y_b).sum().item()\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for (pc_b, d_b), y_b in val_loader:\n",
        "            pc_b, d_b, y_b = pc_b.to(device), d_b.to(device), y_b.to(device)\n",
        "            preds = model(pc_b, d_b).argmax(dim=1)\n",
        "            total += y_b.size(0)\n",
        "            correct += (preds == y_b).sum().item()\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch:2d} — Train: {train_acc*100:.2f}%  Val: {val_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "collapsed": true,
        "id": "n_-9cIRtGI73",
        "outputId": "9f2d2af2-331f-477d-b7a8-ff1d2cac41c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1 — Train: 48.95%  Val: 54.78%\n",
            "Epoch  2 — Train: 55.26%  Val: 60.72%\n",
            "Epoch  3 — Train: 59.77%  Val: 63.24%\n",
            "Epoch  4 — Train: 62.44%  Val: 64.68%\n",
            "Epoch  5 — Train: 64.12%  Val: 65.60%\n",
            "Epoch  6 — Train: 65.43%  Val: 66.33%\n",
            "Epoch  7 — Train: 66.47%  Val: 67.02%\n",
            "Epoch  8 — Train: 67.25%  Val: 67.48%\n",
            "Epoch  9 — Train: 67.92%  Val: 67.76%\n",
            "Epoch 10 — Train: 68.59%  Val: 68.07%\n",
            "Epoch 11 — Train: 69.02%  Val: 68.32%\n",
            "Epoch 12 — Train: 69.59%  Val: 68.50%\n",
            "Epoch 13 — Train: 69.95%  Val: 68.66%\n",
            "Epoch 14 — Train: 70.31%  Val: 68.66%\n",
            "Epoch 15 — Train: 70.70%  Val: 68.91%\n",
            "Epoch 16 — Train: 71.06%  Val: 69.14%\n",
            "Epoch 17 — Train: 71.25%  Val: 69.27%\n",
            "Epoch 18 — Train: 71.57%  Val: 69.35%\n",
            "Epoch 19 — Train: 71.88%  Val: 69.43%\n",
            "Epoch 20 — Train: 72.11%  Val: 69.57%\n",
            "Epoch 21 — Train: 72.32%  Val: 69.51%\n",
            "Epoch 22 — Train: 72.56%  Val: 69.63%\n",
            "Epoch 23 — Train: 72.77%  Val: 69.75%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-5-1841119027.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpc_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-4008170944.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pc_seq, delta_seq)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             )\n\u001b[0;32m--> 370\u001b[0;31m         return F.conv1d(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Weights"
      ],
      "metadata": {
        "id": "xn4PgaY_r7sT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE MODEL WEIGHTS\n",
        "MODEL_PATH = \"prefetch_cnn_weights.pth\"\n",
        "\n",
        "# Save just the state_dict (Only the learned weights)\n",
        "torch.save(model.state_dict(), MODEL_PATH)\n",
        "# torch.save(model, \"prefetch_cnn_full.pth\") # For the full architecture\n",
        "print(f\"Model weights saved to {MODEL_PATH}\")\n",
        "\n",
        "# DOWNLOAD IN COLAB\n",
        "from google.colab import files\n",
        "files.download(MODEL_PATH)\n",
        "# files.download(\"prefetch_cnn_full.pth\") # Or for the full model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "uYiYdMOtr8xt",
        "outputId": "e8e2dded-2ee5-4b8c-c80e-c6f537c44a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights saved to prefetch_cnn_weights.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_fc18816b-2bd9-41c0-8f78-cd7a06bbfbb3\", \"prefetch_cnn_weights.pth\", 8224452)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}